

\chapter{Introduction \& Motivation}
%%%%%%%%%%%%
%  (start with some kind of epigraph, maybe Tufte?)
%  cite: maybe Marcelo's paper on mapping, DOT, libmapper
%	look at Joe's 1-3
%	1: separate parts
%	S. Mann, “Natural interfaces for musical expression: Physiphones and a physics-based organology,” in Proceedings of the 2007 Conference on New Interfaces for Musical Expression (NIME-07), (New York, USA), pp. 118–123, 2007.
%	2: controller any arbitrary shape
%	E. R. Miranda and M. M. Wanderley, New Digital Instruments: Control and Interaction Beyond the Keyboard, vol. 21 of The Computer Music and Digital Audio Series. Middleton, Wisconsin, USA: A-R Editions, Inc., 2006.
%	3: mapping
%	J. Ryan, “Some remarks on musical instrument design at STEIM,” Contemporary Music Review, vol. 6, no. 1, pp. 3–17, 1991.
%	probably use marcelo's paper instead
%%%%%%%%%%%%
For the vast majority of human history a musical instrument was definitively both the physical object with which the musician interacted \emph{and} the direct source of the sound created: a violin with vibrating strings, a reeded saxophone, a timpani with its membrane, etc.  With the advent of electronic sound the late 19\textsuperscript{th} century 
it became possible for interactive objects to separate from the sound producing devices they control. %\tocite{Chadabe, Joel (February 2000), The Electronic Century Part I: Beginnings, Electronic Musician, pp. 74–90}
As technological development progressed, so did the capacity to divide musical instruments into independent parts. With digitization it is now not only possible to arbitrarily connect a control element to any sound synthesis dimension, but also to modify this association according to the whims of the user. Since mechanical linkages are no longer necessary in the design of musical instruments, control surfaces can, and often do, take on a variety of wild and arbitrary shapes and modes of interaction. %\tocite{somebody to support this, maybe International Conference on New Interfaces for Musical Expression. [Online]. Available: http://www.nime.org/. Accessed June 16, 2007.}
All that is necessary is for these devices to output some kind of electronic signal that other, sound producing instruments can accept. With no obvious means of implementation, the success or failure of these new digital musical instruments (DMIs) often depends on how artfully their output signals are ``mapped" to synthesis parameters.

More and more frequently, the mapping itself becomes part of the expressive element of a musical work, %\tocite{}
associating itself with both composition and performance with certain DMIs. Thus is becomes necessary for mapping to be modular and interactive: sometimes poured over in composition studios, sometimes edited mid-piece. Musicians are not necessarily computer programmers, so ideally musical mapping would be something in which non-experts in DMI design could participate. This means that, on top of the low-level layer of interactive mapping that is simply telling a machine to connect certain signals to others in certain ways, there needs to exist an interface to make such an activity easy, logical, intuitive and in line with the artistic process.

As the actual act of mapping is as expansive and nebulous as the instruments it hopes to assist. The design of such an interface presents many interesting challenges


	What are useful features of a graphical interface for musical mapping?

\section{Context and Motivation}

\section{Project Overview}

\section{Thesis Overview}

\section{Contributions}