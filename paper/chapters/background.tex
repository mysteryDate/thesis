%!TEX root = ../thesis.tex
\chapter{Background}

Dynamic mapping is becoming an increasingly important requirement for digital musical instruments. This chapter surveys currently available tools that allow for manipulation of musical and non-musical networks in real time. The first section presents a review of mapping itself, both from a theoretical and a musical standpoint. This portion also introduces the libmapper application programming interface. The second section reviews relevant work in the visual representation of information. The following portion describes applicable techniques in user interface design. Finally, a review of user interfaces for mapping is presented.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Mapping}

At the most fundamental level, \emph{mapping} is the act of associating two or more sets of information. Mappings can be mathematical, computational, linguistic (like translation), geographic, or even poetic\footnote{What is metaphor if not the association of unlike things?}. Within the context of DMI design mapping is the relationship between sensor outputs and synthesis inputs. The entire character of a new instrument can be drastically altered though mapping, even while control surface and sound source are held constant \shortcite{hunt_mapping_is_important}. As a result, the theoretical formalism of mapping becomes yet another necessary tool in the modern instrument designer's arsenal.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Mapping theory}
	\label{sec:mapping_theory}

	\subsubsection{Mapping as function and mapping cardinality}

From the perspective of mathematics, the term \emph{mapping} is very nearly synonymous with \emph{function} \cite{native_set_theory}, as both describe how one set of numbers corresponds with another. The first group is commonly referred to as the \emph{domain} and the second as the \emph{codomain} or \emph{range}. An in-depth review of functions in mathematics is beyond the scope of this thesis, however a few fundamental examples will be useful for reference in section \ref{sec:mappingforDMIs}. The following are instances of two basic types of mathematical functions:

\begin{equation} y = 2x - 1 \label{eq:one-to-one} \end{equation} 
\begin{equation} y = x^2  \label{eq:many-to-one}  \end{equation}

Each function takes a single input value (\emph{x}) and \emph{maps} that number onto its range (\emph{y}). 
%For example, an input of \textbf{5} maps to \textbf{9} in equation \ref{eq:one-to-one}, while the same input results in an output \textbf{25} for equation \ref{eq:one-to-many}. 
The fact that each of these equations take in only a single number as input, and output a single number in turn, means they can be graphed in a two dimensional space. This is not necessarily the case, as functions can input and output lists of numbers (vectors). Mathematically they are not very interesting, but they represent two fundamentally different \emph{kinds} of functions.

\begin{figure}[h]
	\centering
	\begin{tikzpicture}
		\begin{axis}[my style, xtick={-2,-1,...,2}, ytick={-2,-1,...,2}, xmin=-2, xmax=2, ymin=-2, ymax=3]
			\addplot[domain=-100:100]{2*x-1}; 
		\end{axis}
	\end{tikzpicture}	
\caption{The function described in equation \ref{eq:one-to-one}, graphed in two dimensions.}
\label{fig:one-to-one_graph}
\end{figure}

For equation \ref{eq:one-to-one} each input value has \emph{one and only one} corresponding output value. The same is true if the function is to be inverted, as each output value corresponds to only one input value. The range is simply a scaled and shifted version of the domain. The mapping's \emph{one-to-one} nature can clearly be seen in figure \ref{fig:one-to-one_graph}. To mathematicians this is known as the mapping's \emph{cardinality}.

\begin{figure}[h]
	\centering
	\begin{tikzpicture}
		\begin{axis}[my style, xtick={-3,-2,...,3}, ytick={-3,-2,...,3}, xmin=-3, xmax=3, ymin=-1, ymax=4]
			\addplot[domain=-3:3]{x^2}; 
		\end{axis}
	\end{tikzpicture}
\caption{Equation \ref{eq:many-to-one} projected on the Cartesian plane.}
\label{fig:many-to-one_graph}
\end{figure}

This is not the case for equation \ref{eq:many-to-one}, for although each input has only one output, single positions in the codomain can have multiple corresponding inputs (e.g. both $3^2$ \emph{and} $-3^2$ are equal to 9). Thus we can consider equation \ref{eq:many-to-one} to be a classical example of a mapping with a cardinality \emph{many-to-one}. In figure \ref{fig:many-to-one_graph} the range of the function is wrapped back onto itself such that a horizontal line could intersect the curve twice.

Two more mapping cardinalities are relevant to instrument design, an example of each:  

\begin{equation} y = \pm\sqrt{x} \label{eq:one-to-many} \end{equation} 
\begin{equation} y = \pm\sqrt{1 - x^2} \label{eq:many-to-many} \end{equation} 

They are not considered to be functions by mathematicians\footnote{In mathematics, a true function can have no more than one output value for every input value.}, but are nonetheless important for our purposes. In equation \ref{eq:one-to-many} a single input can result in multiple outputs (an input of 4 results in the output of \emph{both} 2 and -2), yet each output has only a single input. This is simply the inverse function of equation \ref{eq:many-to-one}, and is an example of a \emph{one-to-many} mapping. On a graph of such a mapping, a \emph{vertical} line may cross at multiple points. The final equation is that of a circle centered at the origin with a radius of one. This is a \emph{many-to-many} mapping, as both it an its inverse result in multiple outputs from a single input.

\begin{figure}[ht]
	\centering
	\begin{tikzpicture}
		\begin{axis}[my style, xtick={-1,...,1}, ytick={-1,...,1}, xmin=-1.5, xmax=1.5, ymin=-1.5, ymax=1.5]
			\addplot[domain=-1:1]{sqrt(1 - x^2)}; 
			\addplot[domain=-1:1]{-sqrt(1 - x^2)}; 
		\end{axis}
	\end{tikzpicture}
\caption{Equation \ref{eq:many-to-many}, a many-to-many mapping.}
\end{figure}

Though a graphical plane is the most common way for mathematicians to visualize two-dimensional functions, drawing the direct association between input and output will be more useful going forward. Figure \ref{fig:types_of_mapping} provides an illustration of such an approach. The astute reader will notice a striking similarity to the GUI view mode described in section \ref{sec:list_view} and these diagrams.  

\begin{figure}[ht]
\centering
	\scalebox{1}{\includegraphics{figures/types_of_mapping}}
\caption{The four mapping classes}
\label{fig:types_of_mapping}
\end{figure}

	\subsubsection{Mapping as association}

In computer science, a mapping is less commonly referred to as a function and more usually called an \emph{associative array} or a \emph{dictionary}, though the word \emph{map} is also used \cite{data_structures}. This type of data structure is generally the most flexible way for computers store information. An associative array consists of key/value pairs, where the \emph{value} is the data to be stored and the \emph{key} is the reference to that data. 

\begin{table}
	\centering
	\Tcaption{An example of key/value pairs (contries and currencies)}
	\label{tab:key_value_pairs}
	\begin{tabular}{l l}
		\hline\hline
		key&value\\
		\hline
		Canada&Dollar\\
		France&Euro\\
		Bahrain&Dinar\\
		Germany&Euro\\
		Angola&Kwanza\\
		USA&Dollar\\
		\hline
	\end{tabular}
\end{table}

In table \ref{tab:key_value_pairs} the data is non-numeric and associations between keys and values are arbitrary (from a mathematical point of view). There obviously exists no distinct function that can transform a countries name into the name of its currency, thus the computer must explicitly remember the associations between the words in the form of a \emph{hash table}. At the lowest level, computers store information on a vast array of zeros and ones, and the value ``Kwanza'' only arises through a non-trivial process of encoding and decoding. In order to retrieve it the computer \emph{must} know where it can be found. The hash table takes the input of a key, finds the address for the value and returns it. In this way the hash table is literally the association between two sets of data and thus the mapping between them. 

The four mapping classes outlined in the above section are not limited to the functional domain. The associative array in table \ref{tab:key_value_pairs} is another example of a many-to-one mapping, as many countries have the same currency name. In this vain a one-to-many mapping could be the same keys with values switched to ``Former Monarchs'' (``France'' would map to both ``Louis XVI'' and ``Napoleon III'', etc), while a value of ``Official Languages'' would be a many-to-many mapping (``Canada'' maps to both ``English'' and ``French'' while both ``Canada'' and ``France'' map to ``French'').

Though most applicably represented in computer science, data structures like associative arrays appear in many other fields. Library card catalogs (one-to-one), multilingual dictionaries (many-to-many) and address books (many-to-one) are all very straightforward instances of key/value pairs. In a library card catalog the call number even acts as a sort of hash table. In a large library, a book that is placed in the incorrect position on the shelves will likely be lost for a very long time. Thus the system must not only remember the keys (titles) and associated values (the books themselves) but also their positions in memory, their call numbers.

%The above concepts from mathematics and computer science supply a base of knowledge for understanding mappings theoretically and provide a starting point for analyzing them in a musical context.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Mapping for digital musical instruments} \label{sec:mappingforDMIs}

With an acoustical musical instrument a musician must interact directly with the physical object that produces the sound. In this context, the concepts of ``control surface,'' and ``synthesis devices'' are not very relevant, as they are intrinsically linked. In the case of an acoustic guitar the pick \emph{could} be considered to be a sort of control device (as it is primarily used for instrumental interaction), with the strings and body a acting as the sound producing section. The problem with this type of approach is that changing the material of the pick, perhaps to give a different feel for the player, will also necessarily modify the sound produced. The same can be said for modifying nearly any aspect of an acoustic instrument: it will change both the control interface and the created sound. This coupling of parameters causes any concept of a \emph{mapping layer} to be irrelevant.

As stated in the introduction, this is not the case for electronic instruments \shortcite{wanderley}. Electronic sensors transduce musical gestures into signals, which are in turn converted into auditory phenomena by amplifiers and speakers. Any arbitrary transformation can happen to the signals\footnote{Especially digital signals, which are remarkable for their robustness and mutability.} in between these two phases. This flexibility is most obvious with outlandish novel instruments like (TODO: maybe pictures?), but is fundamentally true for any electronic instrument. An electric guitar senses gesture with a magnetic pickup that transforms the signal of a vibrating string into an electronic signal, which is made audible by an amplifier. Though this can happen directly, more or less reproducing the sound of an acoustic guitar, it is also possible to greatly modify this signal before it is amplified, creating tones that may be unrecognizable as the original acoustic instrument.

	\subsubsection{The mapping layer}

In response to the importance of this uncoupling of parameters, electronic instruments are often conceptualized as having three independent layers \cite{gestural_control_sound_synthesis}: (TODO diagram)

	\begin{itemize}
		\item The ``gestural controller'': The device with which the musician interacts directly. It generally has sensors that collect gestural data and can provide haptic feedback. The generated signals are output into the mapping layer.
		\item The ``sound generation unit'': This device receives input signals from the mapping layer and uses them to generate sound. This layer can contain melody generating algorithms, sound modifying effects, physical models of acoustical instruments or any other construct that is directly used to produce sound.
		\item The ``mapping layer'': The abstract space that receives input signals from the gestural controller and outputs to the sound generation unit. These signals can be connected and modified independently of actions in the other two layers.
	\end{itemize}

As can be seen above, the words ``output'' and ``input'' become ambiguous, whether one is speaking from the perspective of devices (control devices \emph{output} signals that are \emph{input} into the synthesis devices) or the perspective of the mapping layer (the mapping receives \emph{input} from the controller which is \emph{output} to the synthesizer). For the detailed analysis of mappings and mapping devices, this can obviously create confusion. To avoid this, signals arriving at the mapping layer from the control surfaces will be referred to as \emph{source signals} and signals sent from the mapping layer to the sound generation units will be called \emph{destination signals} for the remainder of this thesis. This follows the nomenclature described in \shortciteN{new_libmapper} and the libmapper API in general.

	\subsubsection{Functional versus systems perspective on mapping}

Both the more mathematical perspective of mapping as functions and the computer science standpoint of mapping as association are relevant to DMI design. These two concepts are often referred to as the \emph{functional} and the \emph{systems} points of view for mapping, respectively \cite{two_types_of_mapping}. 

Once two signals are connected, say the position of a knob and the cutoff frequency of a low-pass filter,\footnote{A standard synthesis parameter that controls the brightness of a sound, think of the difference between the vowel `o' in `food' (low cutoff) and the vowel `a' in `sad' (high cutoff).} it is very possible that the raw numbers sent from the knob are not appropriate as input for the filter. It may be that the knob transmits numbers ranging from 0 - 127 ($2^7$) and the filter accepts numbers from 0 - 1023 ($2^{10}$). As a result the filter will always be more or less closed no matter how the user turns the knob. To account for this, the mapping needs to \emph{scale} the source signal (by a factor of 8) to fit the destination range. This is a functional kind of mapping, analogous to section \ref{sec:mapping_theory}. The source signal may need to be transformed in many ways. 

The other, higher-level perspective on mapping deals with the actual connection of source to destination signals. On any mapping network there can exist several devices, each with numerous signals. The act of associating devices with devices, signals with signals can drastically change the character of a DMI or group of DMIs. This is known as the systems perspective on mapping. It is necessary for libmapper and the GUI to be able to assist with both kinds of mappings.

	\subsubsection{Mapping strategies}

For expressive musical networks, simple one-to-one mappings are often insufficient.  \citeN{describing_mappings} argues that it is extremely rare to find such associations in acoustic instruments, as the control parameters are usually tightly coupled with several acoustic dimensions. Interfaces with hundreds of knobs and sliders, each one connected to a single sound parameter have thus been found to ``...hinder rather than help expressive musical behavior.'' \citeA{describing_mappings} In practical experiments where mappings of varying complexity are compared, the most complex were generaly found to be the most expressive and useful \cite{mapping_complexity_experiments}. However, \citeN{interpolated_mappings} states that mappings need to be simple enough for the performer to comprehend them. \citeANP{interpolated_mappings} argues for ``...static mappings over dynamic, and simple over complex'' and proposes an algorithmic solution to compute them. These ``interpolated mappings'' are generated by associating single points in the source and destination spaces (i.e. certain performer gestures with certain sounds) and mathematically filling in the spaces between.

One proposed solution to the cognitive complexity of associating many source and destination signals is to create a second mapping layer \shortcite{wanderley}. Instead of dealing with raw sensor output, like acceleration and inclination, musicians can interact with more interesting gestural information such as ``jab'' or ``left-arm swing.'' These ``cooked'' parameters are argued to be more meaningful and useful musical information than the raw signals. This approach is explored in \citeN{mapping_layers} for mapping both to audio and visual synthesis. The conventional wisdom that mappings need to be complex, yet transparent and meaningful all point to the necessity of a tool for the intuitive and expressive configuration of mappings.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{libmapper}

The McGill Digital Orchestra project\footnote{The McGill Digital Orchestra. [Online]. Available: \url{http://www.music.mcgill.ca/musictech/DigitalOrchestra/}. Accessed July 9, 2013} began in 2006 with the aim of helping researchers  and performers in music technology to work collaboratively in creating hardware and software solutions for live performance with digital technology. The libmapper project began in response to the difficulty of creating dynamic musical mappings in a collaborative setting \shortcite{malloch}. In its most basic state, libmapper is a library for connecting things. As described by its website: 

\begin{quote} 
``libmapper is an open-source, cross-platform software library for declaring data signals on a shared network and enabling arbitrary connections to be made between them. libmapper creates a distributed mapping system/network, with no central points of failure, the potential for tight collaboration and easy parallelization of media synthesis. The main focus of libmapper development is to provide tools for creating and using systems for interactive control of media synthesis.''\footnote{libmapper: a library for connecting things. [Online]. Available: \url{libmapper.org}. Accessed June, 2013}
\end{quote}

Without libmapper, DMI designers are usually required to ``hard-code'' mappings into their designs. This has the disadvantage of being slow to modify, as it might be necessary to re-compile\footnote{A process in which human-readable code is translated into something the computer can understand. This can take anywhere from a few seconds to days.} code any time a change is made. If the DMI is built in a development environment like Max/MSP modifications can be more quickly implemented. Max/MSP is a ``high-level'' abstraction on top of machine readable code, so Max/MSP programs are prone to slowness and cross-compatibility issues, inhibiting collaboration \shortcite{jamoma}. In either implementation it is difficult for someone other than the original designer to modify mappings.

As a C\footnote{An extremely popular, multi-purpose programming language.} library, libmapper does not introduce many abstractions on top of the data and can work quickly. Any device that embeds libmapper in its code can communicate with other devices that have done the same. In a libmapper network devices communicate with one another directly, as opposed to through some centralized network device. This means that less data overall needs to be sent over the network, and failure of a single device (like the router) will not crash the entire system \shortcite{new_libmapper}, an especially dire situation during live performance.

Another advantage of libmapper, which is especially relevant to this project, is the ability to create an administrative device. These ``monitors'' can query libmapper devices for data, and thus collect data on the network overall. Monitors also are able to create, destroy and modify connections on the network. This allows for external visualization and control of a libmapper network.

	\subsubsection{Open sound control and libmapper syntax}

Like any communication, communication between digital devices functions well only when the devices speak the same language. In the Internet age this becomes particularly relevant: the vast array of continuously connected devices, sending and requesting information would instantly collapse if every developer coded to his or her own idiosyncrasies. To prevent this, computer scientists make use of various communication ``protocols'' when creating software. Hypertext Transfer Protocol (HTTP) is the most famous example of such a system.

At its core, libmapper builds its on language on top of the Open Sound Control (OSC) protocol, as described by \shortciteN{osc}. OSC defines the format for messages that are sent between sound producing devices (as implied by the name), but can also be used for related multimedia devices such as stage lights or vibrating motors. It provides means for flexible, high-resolution communication and was intended to replace MIDI\footnote{MIDI Manufacturers Association - The official source of information about MIDI. [Online]. Available: \url{www.midi.org}. Accessed July 11, 2013}, the 30-year-old standard for musical instrument communication. 

OSC formats messages much like Internet URLs, arbitrary strings of characters separated by `/' characters. libmapper messages also take on this format, using the structure to expose hierarchy of signals:

	\begin{itemize}
	\item\url{tstick.1/raw/accelerometer/1/x}: The data for the `x' dimension of the first accelerometer of the first instrument of class ``tstick'' on the network (see TODO for a description of the gestural controller T-Stick). Here the word ``raw'' denotes that no pre-processing has been applied to this signal. 
	\item\url{tstick.1/raw/accelerometer/2/y}: A signal transmitting the data for the same instrument as above, but the `y' dimension of the second accelerometer.
	\item\url{tstick.1/cooked/accelerometer/2/amplitude}: A ``cooked'' signal. All three dimensions of accelerometer 2 are combined to compute the overall acceleration of the point. These signals can also be cooked to expose angle and elevation as signals.
	\item\url{granul8.2/filter/evelope/frequency/low}: The data for the low-end cutoff for the shape of the filter for the instrument named ``granul8.2'' (a granular synthesizer, thus a destination device).
	\end{itemize}

This structure of signal names aims to be semantically relevant, and allows a GUI to display hierarchical structure of networks. Any one of the above signals transmits not only the signal's value, but also metadata. Signal metadata usually includes data type, length (single number vs. vector), units like volts or meters per second, maximum value and minimum value. Designers can ``tag'' signals with any extra metadata they may wish to add, such as physical position, color or owner's name. In the GUI it is necessary to allow users to view and manipulate any arbitrary kind of signal metadata.

To make signal names as coherent and consistent as possible, libmapper makes use of the \emph{Gesture Description Interchange Format} (GDIF) \shortcite{GDIF}, which provides a standard for motion capture data. Structures are given short, semantically relevant names. GDIF also provides a standard vocabulary for describing motion with dimensions such as ``weight,'' ``space,'' ``time'' and ``flow.'' Though these standards are not enforced, as libmapper signals can be given any sort of names by their creators, most extant libmapper-enabled devices use them.

	\subsubsection{Structure of libmapper networks}

In order to maintain internal consistency, libmapper introduces a naming convention of its own. At the heart of any libmapper network are \emph{signals}, defined in \citeN{new_libmapper} as:
\begin{quote}
``Data organized into a time series. Conceptually a signal is continuous, however our use of the term signal will refer to discretized signals, without assumptions regarding sampling intervals.''
\end{quote}
Here \shortciteANP{new_libmapper} are referring to digital as opposed to analog signals (hence the use of the term ``discretized''). Notice how signals are not necessarily numeric by this definition, though they will almost certainly will be going forward. Signals are the only information actually passed from control surfaces to synthesizers, all other data structures exist to organize and label them. \emph{Source signals} is data entering libmapper from control surfaces while \emph{destination signals} belong to synthesizers and receive data. A \emph{connection} is a bridge between two signals. Once a connection is created within libmapper, a source signal begins sending its data to a destination signal. A single source signal can be connected to many destination signals (a one-to-many mapping), but at the time of the writing of this document single destination signals cannot receive input from many source signals (a many-to-one mapping). Justification for this lack of functionality is discussed in \shortciteN{new_libmapper}.

\emph{Devices} are essentially groups of signals. A device often has some kind of physical entity that makes the grouping logical, e.g. the ``T-Stick,'' which has many ``child'' signals. Within software the grouping is usually a discreet computer program. With development environments like Max/MSP users are free to group signals into devices however they may wish. As mentioned previously, libmapper devices do not send all signal data to some centralized router, and instead work directly with one another. In order to accomplish this devices must be explicitly \emph{linked}. Figure \ref{fig:libmapper_devices} demonstrates instances of libmapper devices, signals, links and connections.

\begin{figure}[ht]
\centering
	\scalebox{1}{\includegraphics{figures/libmapper_devices}}
\caption{A simple libmapper network}
\label{fig:libmapper_devices}
\end{figure}

Devices and signals can carry a variety of \emph{metadata}. Devices usually list the number of child signals they possess and their location on the network (IP address and port). As previously stated users can tag devices and signals with arbitrary metadata. Connections have a much more specific set of metadata.

	\subsubsection{Connection properties}

Creation of links and connections is mapping from the systems perspective, but libmapper also allows for functional mapping through the modification of connections. This can be accomplished by altering certain properties possessed by every libmapper connection:

\begin{itemize}
	\item\textbf{Expression}: A mathematical equation relating the source ($x$) to destination ($y$) values. An expression of $y = x$ will simply pass through source values, while an expression of $y = 3x + 2$, will apply a linear transformation to the source data (e.g. a value of 1 will be output as 5). libmapper supports a variety of expressions, including exponential functions, trigonometric relations, comparison operators, derivation and integration. 
	\item\textbf{Range}: An array of four numbers containing the user-specified maximum and minimum values for both the source and destination signals.
	\item\textbf{Mode}: The type of connection, this influences the effect of the expression and range properties and can be one of four categories:
	\begin{itemize}
		\item \emph{Linear}: libmapper automatically scales the output such that it fits the destination range, based on the source range. For example, if a certain connection has a source range of $[0, 1]$, and a destination range of $[5, 10]$, libmapper will automatically apply an expression of $y = 5x + 5$, such that the minimum and maximum source values will correspond to the minimum and maximum destination values respectively. A source value that is outside of this source range will result in a destination value that is also outside of the range. In this mode the user cannot directly modify the expression. 
		\item \emph{Calibration}: The same as the linear mode except the source range parameter is ignored. libmapper instead polls the source signal to find the source range directly.
		\item \emph{Bypass}: Source values are sent directly through to the destination signal, as would happen with an expression $y = x$.
		\item \emph{Expression}: The user is able to set the expression to any arbitrary relation.
	\end{itemize}
	\item\textbf{Boundary}: What is to happen to data values when they extend beyond the destination range. There are four options:
	\begin{itemize}
		\item\emph{None}: Values are passed through unchanged.
		\item\emph{Clamp}: Values outside of the boundary are constrained to that value.
		\item\emph{Mute}: No values outside of the boundary are passed to the output.
		\item\emph{Wrap}: Values exceeding the maximum are ``wrapped'' back to the minimum bound and vice versa.
		\item\emph{Fold}: When the signal passes outside of the boundary, the value is inverted back onto the destination range. 
	\end{itemize}
	\item\textbf{Mute}: A true-or-false value muting and un-muting data sent over the connection.
	\item\textbf{Send as instance}: Not all signals on libmapper networks are unique and long lasting, a good example being a keypress on a keyboard. During the keypress, data like aftertouch and release can be sent, making it a bona fide signal. However, musicians constantly create and complete keypress events during performance with keyboard instruments. To maintain every keypress as a unique signal with unique metadata would be tremendously unhelpful for mapping. Also, forcing a user to map every keypress event individually would make live performance impossible.

	To support this, libmapper gives connections the \emph{send as instance} property. Sending data as an instance means that libmapper treats the connected signals as instances of a general class of signals. New instances of a signal class will be treated like previous instances and do not need to be mapped individually.
	\item\textbf{Link scope}: Not a property of connections, but of links. By default links are ``scoped'' to notify destination devices of the creation and destruction of signal instances on linked source devices. For intermediate devices, ones that function as both source and destination, this may not be the desired behavior. If device \url{A} is linked to intermediate device \url{B}, which is in turn linked to device \url{C}, then \url{C} will not be notified of instance events on \url{A} with default link scope settings. The user can modify the scope of link \url{B} $\rightarrow$ \url{C} to include \url{A} if desired.

\end{itemize}

	\subsubsection{libmapper bindings}

A final crucial libmapper feature is its multi-language \emph{bindings}. The C language is ``low-level,'' in that it is very procedural and does not allow for very abstract data structures. This makes it extremely flexible, but difficult and time consuming to use. To make libmapper more friendly for different kinds of developers, ``bindings'' have been created for the higher-level 
Python\footnote{Python Programming Language - Official Website. [Online]. Available: \url{http://www.python.org/}. Accessed July 17, 2013} 
and 
Java\footnote{java.com: Java + You. [Online]. Available: \url{java.com/en}. Accessed July 17, 2013} 
programming languages. libmapper functions are bound to other languages using the 
Simplified Wrapper and Interface Generator (SWIG)\footnote{Simplified Wrapper and Interface Generator. [Online]. Available: \url{http://www.swig.org/}. Accessed July 17, 2013}.
SWIG automatically writes a kind of dictionary that interprets function calls from other languages to the original C. Automatically generated files sit in-between the controlling code and the original library. 

Though concept of ``mapping'' itself is extremely abstract, the libmapper API places it into a concrete context. libmapper is not only means of organizing networks though the creation and destruction of links and connections, it is also a tool for customizing response by its support for modifying connection properties. In this way it can serve both the high-level systems perspective and the low-level functional view of mapping. Though designed for musical devices, the API's loose framework could readily be applied to any type of multimedia system. libmapper is an extremely powerful, flexible tool and requires a user interface that can elegantly deploy its full range of capabilities.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Data Visualization}

The graphical user interface described in this thesis is a purely visual interface. No means of auditory or haptic response was implemented, or even seriously considered. Creating an auditory tool for controlling musical instruments is obviously problematic and most personal computers provide no means of produce haptic feedback. This obviously limits the usable dimensions, but also greatly simplifies the problem of how to best represent the tremendous variety of libmapper networks.

Fortunately graphic designers and statisticians have already deeply probed the problem of how to best display data visually. It is necessary here to briefly review some of this work, especially the techniques relevant to the creation of a libmapper GUI and visual systems from which inspiration was drawn.

\subsection{Graphical dimensions}

The visual dimension can be broken down into many sub-dimensions. These dimensions are not fully separable, but doing so creates a useful paradigm for understanding and creating solutions for our visual problem. \citeN{bertin_graphics} presents a simple vocabulary for categorizing graphical objects and relationships.

\begin{table}
	\centering
	\Tcaption{Bertin's graphical relationships}
	\label{tab:graphical_relationships}
		\begin{tabular}{l  l}
		\hline\hline
		\textbf{Marks}& Points, lines and areas\\
		\textbf{Positional}& 1-D, 2-D and 3-D\\
		\textbf{Temporal}& Animation\\
		\textbf{Retinal}& Color, shape, size, saturation, texture and orientation\\
		\hline
		\end{tabular}
\end{table}

\begin{wrapfigure}{r}{0.4\textwidth}
	\centering
		\includegraphics[width=0.4\textwidth]{figures/accuracy_of_visual_dimensions}
		\caption{Cleveland and McGill's rankings for quantitative perceptual tasks.}
		\label{fig:accuracy_of_visual_dimensions}
\end{wrapfigure}

Visual presentations use marks to encode information by way of their positional, temporal and retinal qualities. In table \ref{tab:graphical_relationships} \emph{retinal} properties are so called because the eye is sensitive to them independently of their position. Though the third positional dimension is relevant and would be useful, it is currently beyond the scope of this research, not to mention the hardware on which the GUI is to run. 


\citeN{cleveland} expand on this vocabulary, enumerating further sub-dimensions of marks and retinal properties. An experiment is described in which subjects are asked the relative values of various visual objects (e.g. the first box is 50\% larger than the box on the left), for various visual dimensions. From the data, they were able to create a ranking of visual dimensions for quantitative information. In figure \ref{fig:accuracy_of_visual_dimensions}, differences between objects are more accurately perceived when the difference is encoded using a variable higher up the chart. Note that variables like shape, texture and opacity are not included. 

\citeN{visual_dimensions} uses this ranking to expand into non-quantitative data sets. Nominal information is that in which elements can be understood to be similar or dissimilar to one another, yet have no definite order or value. libmapper uses nominal information in the form of device, signal, link and connection names, as well as connection modes and boundary conditions. Ordinal data fits between quantitative and nominal, ordinal items are understood to be greater than or less than one another, while having no definite numerical ratios. If multiple devices of the same class are present on the same libmapper network, libmapper will append ordinal numbers to the end of their device names (e.g. \url{tstick.1}, \url{tstick.2} and \url{tstick.3}).

\begin{table}
\setlength{\tabcolsep}{12pt}
	\centering
	\Tcaption{Mackinlay's Graphical Rankings}
	\label{tab:graphical_rankings}
		\begin{tabular}{l l l}
		\textbf{quantitative}&	\textbf{ordinal}	&	\textbf{nominal}\\
		\hline\hline
		position 			& 	position 			&	position 		\\
		length 				& 	density 			&	color hue 		\\
		angle 				& 	color saturation 	&	texture 		\\
		slope				&	color hue 			&	connection 		\\
		area				&	texture				&	containment 	\\
		volume				&	connection 			&	density 		\\
		density				&	containment 		&	color saturation\\
		color saturation	&	length 				&	shape 			\\
		color hue			&	angle 				&	length 			\\
		texture				&	slope 				&	angle 			\\
		\emph{connection}	&	area 				&	slope 			\\
		\emph{containment}	&	volume 				&	area 			\\
		\emph{shape}		&	\emph{shape} 		&	volume 			\\
		\hline
	\end{tabular}
\end{table}

In table \ref{tab:graphical_rankings}, items in italics are considered unsuitable by Mackinlay. Though position is the most accurate dimension for all types of data, dimensions like \emph{length} differ widely. For the visualization of libmapper networks, it is often necessary to encode many dimensions of data onto a single mark. Devices, signals, connections and links all have a set of metadata with quantitative, ordinal and nominative information. In the design of an effective GUI it will be necessary to properly associate high-accuracy visual dimensions to network properties that require them and reserve low-accuracy dimensions for those that do not. In this way the problem of this thesis conveniently becomes one of mapping: how can we best correlate visual dimensions with properties of libmapper networks?

\subsection{Relevant visualization techniques and systems}

	\subsubsection{Encoding Color}

``Color'' itself is a multi-dimensional phenomenon that does much to communicate information in modern user interfaces. Since color was an uncommon feature of computer displays at the time neither \citeN{bertin_graphics} nor \citeN{cleveland}  explore its use in depth. \citeANP{cleveland} simply state that it is not good for encoding quantitative information. \citeN{visual_dimensions} elaborates on this, breaking color into ``hue'' and ``saturation,'' upgrading its use for ordinal and nominal data. 

\citeN{tufte2} provides a definite procedure for incorporating color into evidence displays\footnote{Tufte's favorite term for data-driven graphics}. Techniques are gleaned from centuries-old map making and applied to computer interfaces. Principal rules, summarized and expanded from \citeN{imhof}, are found to be (paraphrased):

	\begin{itemize}
		\item \emph{First rule}: Bright colors are painful when used uninterrupted over large areas or when placed adjacent to each other, but can be extremely powerful when used sparingly while accompanied by dull tones.
		\item \emph{Second rule}: Light, bright colors produce unpleasant results when accompanied with the color white.
		\item \emph{Third rule}: Background and base colors should be muted or neutral. For this reason, \emph{gray} is regarded to be the most versatile of colors.
		\item \emph{Fourth rule}: Two or more large, enclosed areas within a single display cause the image to fall apart. Unity can be maintained if the colors of one section are interspersed throughout the other. ``All colors of the main theme should be scattered like islands in the background color.''
	\end{itemize}

	\subsubsection{Links and causal arrows}

For the visualization of networks, the idea of a visual ``connection'' becomes very important. This linking action is usually accomplished by an arrow-like object in evidence displays. \citeN{tufte1} enumerates numerous guidelines for incorporating line-like objects into presentations. Again drawing inspiration from map making (an obvious inspiration for ``mapping''), the use of differentiation among linking arrows is greatly emphasized: ``Nouns name a specific something; arrows and links are too often non-specific, generic, identical, undifferentiated, and ambiguous.'' The use of many line properties, such as dashing, arrow-heads and color can better illustrate a variety of influences in a linked chart.

\citeANP{tufte1} also cautions against using heavy line weights when unnecessary, as it effectively decreases display resolution. Thick lines are also more likely to create $1 + 1 = 3$ noise, or the effect of negative space acting as a display feature.

\begin{figure}[ht]
\centering
	\includegraphics[width=0.8\textwidth]{figures/1and1equals3}
\caption{An example of Tufte's $1 + 1 = 3$ noise}
\label{fig:1and1equals3}
\end{figure}

In figure \ref{fig:1and1equals3} the negative space between the two lines appears as its own white line, as opposed to simply empty space. In displays with numerous or thick lines this can cause negative space to compete with informative features, attenuating the overall effectiveness of the display. $1 + 1 = 3$ noise plagues dense computer user interfaces, borders and other non-essential display features should be lightened, thinned and removed when at all possible.

	\subsubsection{Hierarchical edge bundling}

Of course, in diagrams with tremendous amounts of connections no amount of thinning and coloration can create an informative display. The technique of hierarchical edge bundling \cite{HEB} groups lines based on adjacency relationships. Displays take advantage of hierarchical information encoded within the dataset. Linking arrows are curved towards other arrows that are connected to related elements. Figure \ref{fig:heb} demonstrates this effect for arbitrary data.\footnote{Images courtesy of: mbostock - The d3 visualization library. [Online]. Available: \url{https://github.com/mbostock/d3/wiki/Gallery}. Accessed July 24, 2013} 

In a libmapper system, this would mean that connections between signals on the same device will be pulled towards one another. If a hierarchical structure exists in the naming convention, connections between related signals will experience an even stronger force between them. For example, the connections from signal \url{tstick.1/raw/accelerometer/1/x} will be bundled tightly with connections from signal \url{tstick.1/raw/accelerometer/1/y}, but less tightly to \url{tstick.1/raw/accelerometer/2/x}. Any of these connections will not be pulled at all towards connections from signals on other devices.

\begin{figure}[ht]
\centering
	\includegraphics[width=1\textwidth]{figures/heb}
\caption{A dense interconnected network displayed with and without hierarchical edge bundling techniques}
\label{fig:heb}
\end{figure}

	\subsubsection{Braun}

Braun is an application for visualizing OSC data flows on a scrolling graph \cite{braun}. Users are presented with options to adjust what dimension is displayed on the y-axis, the x-axis being reserved for time. Multiple data flows can be viewed on the same set of axes, and time scales can be set arbitrarily, giving the users an overall impression of trends in OSC messages over their networks. An extremely simple visualization, it creates a sort of oscilloscope, but for network OSC data.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{User Interface Design}

\subsection{A brief history of electronic user interfaces}
\subsection{Task analysis}
\subsection{Recall and recognition?}
\subsection{Collaborative network interfaces}
	MPG Care Package \shortcite{MPGcarepackage}
\subsection{The model-view-controller architecture}
	MVC Krasner Pope \shortcite{MVC_krasnerpope}
\subsection{User centric design}
\begin{enumerate}
	\item Organizational context \shortcite{usd}
	\item Usability testing \shortcite{usd_corry}
	\item Information professionals \shortcite{usd_schulze}
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Relevant User Interfaces}
\label{sec:similar_interfaces}
\begin{enumerate}
	\item Inclusive interconnections \shortcite{inclusiveinterconnections}
	\item Sense Stage \shortcite{senseStage}
\end{enumerate}


\subsection{Junxion}
	Junxion \shortcite{junxion}
\subsection{Osculator}
	Osculator: mapping OSC stuff \shortcite{osculator}
\subsection{Other similar interfaces}
	\begin{enumerate}
	\item mpgcarepackage?
	\item Integra \shortcite{integra}
	\item Eaganmatrix: GRID VIEW! \shortcite{eaganmatrix}
	\item Patchage: a linking, dragging, connecting interface \shortcite{patchage}
	\end{enumerate}
\subsection{Prior interfaces for libmapper} \label{sec:priorGUIs}
	Vizmapper \shortcite{vizmapper}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Summary}

Music technology is an inherently interdisciplinary field
	